{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolinocroustibat/movies-palettes/blob/main/movies_palettes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VzeA6NjiyDe"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfNR1QOyvsay"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from pathlib import Path, PosixPath\n",
        "from PIL import Image\n",
        "from skimage import feature, color\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-babtiFgEL"
      },
      "source": [
        "# Configuration constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DlXkgiZF70G"
      },
      "source": [
        "*   **`RESIZE_W` and `RESIZE_H` (Reduced Frame Size)**\n",
        "\n",
        "  This determines the resolution of each frame after downsampling. A reasonable value should:\n",
        "    - Retain enough details for meaningful clustering.\n",
        "    - Eliminate excessive computational overhead from large frame sizes.\n",
        "\n",
        "  Suggested Value: 160 x 90 (W x H)\n",
        "  - This keeps the aspect ratio of typical widescreen content (16:9).\n",
        "  -\tAt 160x90, you get 14,400 pixels per frame, which is sufficient for clustering dominant colors while ensuring faster processing.\n",
        "\n",
        "*  **`FRAME_SKIP` (Frames Skipped)**\n",
        "\n",
        "    This determines how many frames you skip between processed frames.\n",
        "  -\tMovies at 24fps typically don’t have significant color changes frame-by-frame.\n",
        "  -\tA higher skip value reduces computation but might miss some rapid scene changes.\n",
        "\n",
        "  Suggested Value: `FRAME_SKIP = 60`\n",
        " \t- This processes 1 frame per 2.5 seconds (approx.), enough to capture major color changes without excessive redundancy.\n",
        " \t-\tFor a 90-minute movie:\n",
        " \t   - Total frames at 24fps:  90 x 60 x 24 = 129,600\n",
        " \t   - With `FRAME_SKIP = 60`, you’ll process around  129,600 / 60 = 2,160  frames per movie.\n",
        "\n",
        "*  **`BATCH_SIZE` (Frames Processed at Once)**\n",
        "\n",
        "  This determines the number of frames processed in a single batch.\n",
        " \t-\tLarger batch sizes are computationally efficient as you can leverage batch processing in libraries like OpenCV.\n",
        " \t-\tHowever, too large a batch size might lead to memory limitations.\n",
        "\n",
        "  Suggested Values:\n",
        "  - For CPU processing, you can try `BATCH_SIZE = 20`.\n",
        "  - For an NVIDIA A100 GPU, which has 40/80GB of VRAM depending on the variant, you can use a significantly larger batch, like `BATCH_SIZE = 32`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcOszJudZMaZ"
      },
      "outputs": [],
      "source": [
        "CLUSTERS_NB = 10\n",
        "CLUSTERS_NB_BW = 4\n",
        "\n",
        "FRAME_SKIP = 60  # Process one frame out of every FRAME_SKIP frames in order to speed up the process\n",
        "# Resize the image to RESIZE_W x RESIZE_H pixels in order to reduce complexity\n",
        "RESIZE_W = 160\n",
        "RESIZE_H = 90\n",
        "BATCH_SIZE = 32  # Number of frames to process in each batch\n",
        "\n",
        "METHOD = \"cv2\" # \"cv2\" or \"sklearn\". sklearn is supposedly more precise, but cv2 seems to give better results\n",
        "\n",
        "# Recalculate a new palette even if it already has one\n",
        "RECALC_PALETTES = False\n",
        "# Calculate only a specific movie\n",
        "MOVIE_TO_PROCESS = None  # Set to None to process all movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazqExcUTobh"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxH6lzywTWCf",
        "outputId": "7c62fa76-e233-48d6-96a4-39c6f1b76420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88U-a-Ri2No"
      },
      "source": [
        "## Google Drive movies path and movies colors list file path\n",
        "\n",
        "> **WARNING**: Don't forget to mount Google Drive first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8lfNyToPsyz"
      },
      "outputs": [],
      "source": [
        "MOVIES_PATH = Path(\"/content/drive/MyDrive/MOVIES/\")\n",
        "FILE_PATH = Path(\"/content/drive/MyDrive/MOVIES/movies_palettes.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmLaqrEzJqBw"
      },
      "source": [
        "# Function to save movies colors list in a JSON file on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ySlHF7SKIm0"
      },
      "outputs": [],
      "source": [
        "def save_as_file(data: dict, file_path: Path) -> None:\n",
        "    \"\"\"Save as JSON file on Google Drive\"\"\"\n",
        "\n",
        "    def convert_numpy_types(obj):\n",
        "        \"\"\"Convert NumPy types to Python native types.\"\"\"\n",
        "        if isinstance(obj, np.bool_):\n",
        "            return bool(obj)\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return obj\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent='\\t', default=convert_numpy_types)\n",
        "    print(f'\"{str(file_path)}\" successfully saved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP9mCshShrNN"
      },
      "source": [
        "# Build analysis file with list of dicts with movies info\n",
        "> **WARNING**: Only to be executed if the file doesn't exist yet, otherwise it will overwrite the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcQ57gEu0FDz"
      },
      "outputs": [],
      "source": [
        "# subdirs: list[PosixPath] = [p for p in MOVIES_PATH.iterdir() if p.is_dir()]\n",
        "\n",
        "# movies: list[dict] = []\n",
        "\n",
        "# for p in subdirs:\n",
        "#     # Try to match both formats:\n",
        "#     # 1. \"Title (Year, Director)\"\n",
        "#     # 2. \"Title (Year)\"\n",
        "#     # Single regex pattern with optional director group\n",
        "#     match = re.search(r\"(.*) \\((\\d{4})(?:\\, (.*))?\\)\", p.name)\n",
        "\n",
        "#     # Extract movie info\n",
        "#     title: str | None = match.group(1) if match else p.name\n",
        "#     year: str | None = match.group(2) if match else None\n",
        "#     director: str | None = match.group(3) if match and match.group(3) else None\n",
        "\n",
        "#     # Get all video files for this movie directory\n",
        "#     file_types: tuple[str] = (\"*.avi\", \"*.mkv\", \"*.mp4\")\n",
        "#     files_paths: list[Path] = []\n",
        "#     for ft in file_types:\n",
        "#         files_paths.extend(p.glob(ft))\n",
        "\n",
        "#     # Get the unique video file path for this movie directory\n",
        "#     if len(files_paths) == 1:\n",
        "#         file_path: Path = files_paths[0]\n",
        "#     else:\n",
        "#       if len(files_paths) == 0:\n",
        "#           status = \"No movie file found\"\n",
        "#           print(f'{status} for \"{title}\"')\n",
        "#       else:\n",
        "#           status = \"More than 1 video file found:\"\n",
        "#           for f in files_paths:\n",
        "#               status += f' \\\"{f.name}\\\"'\n",
        "#           print(status)\n",
        "\n",
        "#     movie: dict = {\n",
        "#         \"title\": title,\n",
        "#         \"status\": status,\n",
        "#         \"director\": director,\n",
        "#         \"year\": year,\n",
        "#         \"path\": str(file_path) if file_path else None,\n",
        "#         \"palettes\": [],\n",
        "#     }\n",
        "#     movies.append(movie)\n",
        "\n",
        "# # Sort alphabetically\n",
        "# movies.sort(key=lambda m: m[\"title\"])\n",
        "\n",
        "# # Save as file\n",
        "# content: dict = {\n",
        "#     \"last_updated\": datetime.now(timezone.utc).isoformat(),\n",
        "#     \"movies\": movies\n",
        "# }\n",
        "# save_as_file(data=content, file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63VwJZRmuRz1"
      },
      "source": [
        "# Optional: analyze frames numbers and length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxDldvKPtAR5"
      },
      "outputs": [],
      "source": [
        "# for m in (pbar := tqdm(movies)):\n",
        "\n",
        "#   pbar.set_description(f'Analyzing \"{m[\"title\"]}\"')\n",
        "\n",
        "#   if m.get(\"path\") and not m.get(\"frames\"):\n",
        "#     cap = cv2.VideoCapture(str(m[\"path\"]))\n",
        "#     m[\"frames\"]: int = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#     fps: float = cap.get(cv2.CAP_PROP_FPS)\n",
        "#     if fps:\n",
        "#       m[\"length\"]: int = int(m[\"frames\"] / fps)\n",
        "\n",
        "# save_as_file(data=movies, file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWXINNXwVrCn"
      },
      "source": [
        "# Read existing movies analysis file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGCOvIQKVqU1",
        "outputId": "a02d3777-88a5-418d-9b23-22593e1e6538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 441 movies from \"/content/drive/MyDrive/MOVIES/movies_palettes.json\".\n"
          ]
        }
      ],
      "source": [
        "with open(FILE_PATH, \"r+\", encoding=\"utf-8\") as f:\n",
        "    content: dict = json.load(f)\n",
        "    movies: list[dict] = content[\"movies\"]\n",
        "\n",
        "print(f\"Loaded {len(movies)} movies from \\\"{str(FILE_PATH)}\\\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_A0rEmV0wLF"
      },
      "source": [
        "# Function to get runtime type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UDMlB9MtGEY"
      },
      "outputs": [],
      "source": [
        "def get_runtype_type() -> str:\n",
        "  if int(os.environ.get(\"COLAB_GPU\", 0)) > 0:\n",
        "    return \"GPU\"\n",
        "  elif \"TPU_DRIVER_MODE\" in os.environ and os.environ[\"TPU_DRIVER_MODE\"] == \"tpu\":\n",
        "    return \"TPU\"\n",
        "  elif \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "    return \"TPU\"\n",
        "  return \"unknown\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkbxsdLa9mlc"
      },
      "source": [
        "# Function to build a UUID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FdmQHY49q9M"
      },
      "outputs": [],
      "source": [
        "def generate_palette_id(title: str, calculation_date: str) -> str:\n",
        "    \"\"\"Generate a short unique identifier for a palette\"\"\"\n",
        "    unique_string = f\"{title}_{calculation_date}\"\n",
        "    hash_object = hashlib.md5(unique_string.encode())\n",
        "    return hash_object.hexdigest()[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNY-5VRFVuWR"
      },
      "source": [
        "# Main logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tNCGJLxLN0C"
      },
      "source": [
        "This is the main logic here. It might takes a few minutes to a few hours per movie file, depending on where it's run.\n",
        "\n",
        "I suggest a GPU on Google Colab as the runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "815Jnr0twumo"
      },
      "outputs": [],
      "source": [
        "def is_black_and_white(cap: cv2.VideoCapture, threshold: float = 0.1) -> bool:\n",
        "    \"\"\"\n",
        "    Determine if a movie is black and white based on the average saturation.\n",
        "\n",
        "    Parameters:\n",
        "    cap (cv2.VideoCapture): The video capture object.\n",
        "    threshold (float): The saturation threshold below which the movie is considered B&W.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the movie is black and white, False otherwise.\n",
        "    \"\"\"\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    sample_frames = min(total_frames, 100)  # Sample up to 100 frames\n",
        "\n",
        "    saturation_values = []\n",
        "    for i in range(0, total_frames, max(1, total_frames // sample_frames)):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        saturation = hsv[:, :, 1].mean() / 255.0  # Normalize to [0,1]\n",
        "        saturation_values.append(saturation)\n",
        "\n",
        "    average_saturation = np.mean(saturation_values)\n",
        "    return average_saturation < threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cE8M76lA8Gt"
      },
      "outputs": [],
      "source": [
        "def get_dominant_colors_cv2(\n",
        "    data: np.ndarray, clusters_nb: int\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"OpenCV version\"\"\"\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "\n",
        "    # Ensure data is float32 for cv2.kmeans\n",
        "    data = data.astype(np.float32)\n",
        "\n",
        "    # cv2.kmeans returns: retval, labels, centers\n",
        "    _, labels, centers = cv2.kmeans(data, clusters_nb, None, criteria, 10, flags)\n",
        "\n",
        "    # Ensure labels are in the same format as sklearn (1D array)\n",
        "    labels = labels.ravel()\n",
        "\n",
        "    # Ensure centers are in the same format as sklearn\n",
        "    centers = centers.astype(np.float64)  # sklearn uses float64\n",
        "\n",
        "    return centers, labels\n",
        "\n",
        "def get_dominant_colors_sklearn(\n",
        "    data: np.ndarray, clusters_nb: int\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Cluster pixels using k-means and return the dominant colors.\n",
        "    Will automatically reduce number of clusters if not enough distinct clusters are found.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray): A 2D array where each row is a pixel in RGB format.\n",
        "    clusters_nb (int): The maximum number of clusters to form.\n",
        "\n",
        "    Returns:\n",
        "    tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
        "        - centers (np.ndarray): The RGB values of the cluster centers.\n",
        "        - labels (np.ndarray): The label of the cluster each pixel belongs to.\n",
        "    \"\"\"\n",
        "    kmeans = KMeans(n_clusters=clusters_nb, n_init=\"auto\")\n",
        "    labels = kmeans.fit_predict(data)\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    return centers, labels\n",
        "\n",
        "\n",
        "def get_dominant_luminances(\n",
        "    data: np.ndarray, clusters_nb: int\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Find the dominant luminance values in an image using k-means clustering.\n",
        "    Returns these luminance values as grayscale RGB values (where R=G=B).\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray): Input image (can be color or grayscale)\n",
        "    clusters_nb (int): Number of luminance levels to identify\n",
        "\n",
        "    Returns:\n",
        "    tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
        "        - centers (np.ndarray): Array of shape (clusters_nb, 3) where each row is\n",
        "          a grayscale RGB value [v,v,v] representing a dominant luminance level\n",
        "        - labels (np.ndarray): Array indicating which cluster each pixel belongs to\n",
        "    \"\"\"\n",
        "    # Convert to grayscale if input is color image\n",
        "    if len(data.shape) > 2:\n",
        "        data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Reshape to 1D array for clustering\n",
        "    data_reshaped = data.reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "    # Define k-means parameters\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "\n",
        "    # Perform k-means clustering on luminance values\n",
        "    _, labels, centers = cv2.kmeans(\n",
        "        data_reshaped, clusters_nb, None, criteria, 10, flags\n",
        "    )\n",
        "\n",
        "    # Sort centers from darkest to lightest\n",
        "    sort_idx = np.argsort(centers.flatten())\n",
        "    centers = centers[sort_idx]\n",
        "\n",
        "    # Convert luminance values to RGB format (all channels equal)\n",
        "    # e.g., luminance value 127 becomes [127, 127, 127]\n",
        "    centers_rgb = np.column_stack([centers.flatten()] * 3)\n",
        "\n",
        "    return centers_rgb, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ermSYWaBUboG"
      },
      "outputs": [],
      "source": [
        "def process_batch(frames: list[np.ndarray], is_bw: bool) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Process a batch of frames at once to extract dominant colors.\n",
        "\n",
        "    Parameters:\n",
        "    frames (list): List of frames to process\n",
        "    is_bw (bool): Whether to process as black and white\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Array of dominant colors found across all frames\n",
        "    \"\"\"\n",
        "    # Stack all frames into a single array\n",
        "    batch = np.stack(frames)\n",
        "\n",
        "    # Resize all frames at once\n",
        "    resized = np.array([cv2.resize(f, (RESIZE_W, RESIZE_H)) for f in batch])\n",
        "\n",
        "    if is_bw:\n",
        "        # Convert to grayscale and process all frames\n",
        "        gray_batch = np.array([cv2.cvtColor(f, cv2.COLOR_BGR2GRAY) for f in resized])\n",
        "        all_pixels = gray_batch.reshape(-1, 1)\n",
        "        centers, labels = get_dominant_luminances(all_pixels, CLUSTERS_NB_BW)\n",
        "    else:\n",
        "        # Convert to RGB and process all frames\n",
        "        rgb_batch = np.array([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in resized])\n",
        "\n",
        "        # Reshape to process all pixels from all frames\n",
        "        all_pixels = rgb_batch.reshape(-1, 3)\n",
        "\n",
        "        # Get dominant colors across all frames at once\n",
        "        if METHOD == \"cv2\":\n",
        "            centers, labels = get_dominant_colors_cv2(all_pixels, CLUSTERS_NB)\n",
        "        elif METHOD == \"sklearn\":\n",
        "            centers, labels = get_dominant_colors_sklearn(\n",
        "                all_pixels, CLUSTERS_NB\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown method: {METHOD}\")\n",
        "\n",
        "    # Sort clusters by frequency\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    sorted_idx = np.argsort(-counts)  # Sort in descending order\n",
        "    centers = centers[sorted_idx]\n",
        "\n",
        "    return centers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj3utgF0xivo"
      },
      "outputs": [],
      "source": [
        "def process_movie(movie: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate the palette for a movie.\n",
        "\n",
        "    This function processes a movie file to extract its dominant color palette.\n",
        "    For black and white movies, it extracts dominant luminance values instead.\n",
        "    The processing is done in batches to improve performance.\n",
        "\n",
        "    Parameters:\n",
        "    movie (dict): A dictionary containing movie information including:\n",
        "        - path: Path to the movie file\n",
        "        - title: Movie title\n",
        "        - palettes: List of previously calculated palettes\n",
        "\n",
        "    Returns:\n",
        "    dict: The input movie dictionary updated with a new palette entry\n",
        "    \"\"\"\n",
        "    start_time: float = time.time()\n",
        "\n",
        "    pbar.set_description(f'Processing movie \"{movie[\"title\"]}\"...')\n",
        "\n",
        "    cap = cv2.VideoCapture(str(movie[\"path\"]))\n",
        "    frames_count: int = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frames_to_process: int = frames_count // FRAME_SKIP\n",
        "    if frames_to_process < 1:\n",
        "        print(f'Movie \"{movie[\"title\"]}\" has less than {FRAME_SKIP} frames, skipping...')\n",
        "        return movie\n",
        "\n",
        "    # Detect if movie is black and white\n",
        "    is_bw: bool = is_black_and_white(cap)\n",
        "    if is_bw:\n",
        "        print(f'Movie \"{movie[\"title\"]}\" is black and white, with {frames_count} frames.')\n",
        "    else:\n",
        "        print(f'Movie \"{movie[\"title\"]}\" is color, with {frames_count} frames.')\n",
        "\n",
        "    frame_nb = 0\n",
        "    all_centers = []\n",
        "    frames_processed = 0\n",
        "\n",
        "    with tqdm(total=frames_to_process, desc=\"Frames processed\") as frame_pbar:\n",
        "        while frame_nb < frames_count:\n",
        "            batch_frames = []\n",
        "            frames_read = 0\n",
        "\n",
        "            # Calculate how many frames we still need to process\n",
        "            remaining_frames = frames_to_process - frames_processed\n",
        "            current_batch_size = min(BATCH_SIZE, remaining_frames)\n",
        "\n",
        "            # Read up to current_batch_size frames\n",
        "            for _ in range(current_batch_size):\n",
        "                if frame_nb >= frames_count:\n",
        "                    break\n",
        "\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nb)\n",
        "                status, frame = cap.read()\n",
        "\n",
        "                if not status:\n",
        "                    frame_nb += FRAME_SKIP\n",
        "                    continue\n",
        "\n",
        "                batch_frames.append(frame)\n",
        "                frames_read += 1\n",
        "                frame_nb += FRAME_SKIP\n",
        "\n",
        "            if not batch_frames:\n",
        "                break\n",
        "\n",
        "            # Process batch and extend results\n",
        "            batch_centers = process_batch(batch_frames, is_bw)\n",
        "            all_centers.extend(batch_centers)\n",
        "            frame_pbar.update(frames_read)\n",
        "            frames_processed += frames_read\n",
        "\n",
        "    if len(all_centers) == 0:\n",
        "        print(f\"No colors extracted for {movie['title']}. Skipping.\")\n",
        "        return movie\n",
        "\n",
        "    # Combine all centers and do final clustering\n",
        "    all_centers = np.vstack(all_centers)\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=CLUSTERS_NB if not is_bw else CLUSTERS_NB_BW, n_init=\"auto\"\n",
        "    )\n",
        "    kmeans.fit(all_centers)\n",
        "    final_colors: np.ndarray = kmeans.cluster_centers_\n",
        "    final_palette = [tuple(map(int, c)) for c in final_colors]\n",
        "\n",
        "    # Calculate the total processing duration\n",
        "    end_time: float = time.time()\n",
        "    duration: int = int(end_time - start_time)\n",
        "    # Calculation date\n",
        "    now: str = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    palette: dict = {\n",
        "        \"id\": generate_palette_id(title=movie[\"title\"], calculation_date=now),\n",
        "        \"calculation_date\": now,\n",
        "        \"calculation_duration_seconds\": duration,\n",
        "        \"runtime\": get_runtype_type(),\n",
        "        \"clustering_method\": METHOD,\n",
        "        \"is_black_and_white\": is_bw,\n",
        "        \"clusters_nb\": CLUSTERS_NB_BW if is_bw else CLUSTERS_NB,\n",
        "        \"frame_skip\": FRAME_SKIP,\n",
        "        \"resize\": {\"width\": RESIZE_W, \"height\": RESIZE_H},\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"colors\": final_palette,\n",
        "    }\n",
        "    movie[\"palettes\"].append(palette)\n",
        "\n",
        "    return movie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbb3DT51S_1E"
      },
      "source": [
        "# Display palette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtqqCPASTCa9"
      },
      "outputs": [],
      "source": [
        "def display_palette(palette: dict) -> None:\n",
        "    # Display metadata\n",
        "    for k, v in palette.items():\n",
        "        if k != \"colors\":  # Skip colors as we'll display them separately\n",
        "            print(f'{k}: {v}')\n",
        "\n",
        "    # Display color swatches\n",
        "    for c in palette[\"colors\"]:\n",
        "        img = Image.new(mode=\"RGB\", size=(200, 30), color=tuple(c))\n",
        "        display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aOcbp1Q1xQj"
      },
      "source": [
        "# Final loop through movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQmBbkMxgqT6"
      },
      "outputs": [],
      "source": [
        "for m in (pbar := tqdm(movies)):\n",
        "    # Skip movies not matching MOVIE_TO_PROCESS, if specified\n",
        "    if MOVIE_TO_PROCESS and m[\"title\"] != MOVIE_TO_PROCESS:\n",
        "        continue\n",
        "\n",
        "    if len(m[\"palettes\"]) > 0 and not RECALC_PALETTES:\n",
        "        print(f'\"{m[\"title\"]}\" already has at least one color palette calculated, skipping...')\n",
        "        continue\n",
        "\n",
        "    if not m.get(\"path\"):\n",
        "        print(f'\"{m[\"title\"]}\" has no filepath, skipping...')\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "\n",
        "      # Debug: display previous palette\n",
        "      if len(m.get(\"palettes\")) > 0:\n",
        "        print(\"Previous palette:\")\n",
        "        display_palette(palette=m[\"palettes\"][-1])\n",
        "\n",
        "      updated_m: dict = process_movie(m)\n",
        "\n",
        "      # Debug: display new palette\n",
        "      if len(m.get(\"palettes\")) > 0:\n",
        "        print(\"Calculated palette:\")\n",
        "        display_palette(palette=m[\"palettes\"][-1])\n",
        "\n",
        "      # Update file data\n",
        "      movies[movies.index(m)] = updated_m\n",
        "      data: dict = {\n",
        "          \"last_updated\": datetime.now(timezone.utc).isoformat(),\n",
        "          \"movies\": movies\n",
        "      }\n",
        "      save_as_file(data=data, file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cim2Z_WAW887"
      },
      "source": [
        "# Test: display colors palettes for each movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7evqEOXX9LQ"
      },
      "outputs": [],
      "source": [
        "for m in (pbar := tqdm(movies)):\n",
        "    if len(m.get(\"palettes\")) > 0:\n",
        "        print(m[\"title\"])\n",
        "        for p in m[\"palettes\"]:\n",
        "          print(f'\\nPalette calculated on {p.get(\"calculation_date\", \"unknown\")}, runtime: {p.get(\"runtime\", \"unknown\")}')\n",
        "          for color in p[\"colors\"]:\n",
        "            img = Image.new(mode='RGB', size=(200,30), color=tuple(color))\n",
        "            display(img)\n",
        "        print(\"\\n-------------------------------------\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GP9mCshShrNN",
        "63VwJZRmuRz1"
      ],
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}