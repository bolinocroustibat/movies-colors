{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolinocroustibat/movies-palettes/blob/main/movies_palettes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VzeA6NjiyDe"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "bfNR1QOyvsay"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade opencv-python\n",
        "# !pip install --upgrade opencv-contrib-python\n",
        "# !pip install scikit-image\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from pathlib import Path, PosixPath\n",
        "from PIL import Image\n",
        "from skimage import feature, color\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   **`RESIZE_W` and `RESIZE_H` (Reduced Frame Size)**\n",
        "\n",
        "  This determines the resolution of each frame after downsampling. A reasonable value should:\n",
        "    - Retain enough details for meaningful clustering.\n",
        "    - Eliminate excessive computational overhead from large frame sizes.\n",
        "\n",
        "  Suggested Value: 160 x 90 (W x H)\n",
        "  - This keeps the aspect ratio of typical widescreen content (16:9).\n",
        "  -\tAt 160x90, you get 14,400 pixels per frame, which is sufficient for clustering dominant colors while ensuring faster processing.\n",
        "\n",
        "*  **`FRAME_SKIP` (Frames Skipped)**\n",
        "\n",
        "    This determines how many frames you skip between processed frames.\n",
        "  -\tMovies at 24fps typically don’t have significant color changes frame-by-frame.\n",
        "  -\tA higher skip value reduces computation but might miss some rapid scene changes.\n",
        "\n",
        "  Suggested Value: `FRAME_SKIP = 60`\n",
        " \t- This processes 1 frame per 2.5 seconds (approx.), enough to capture major color changes without excessive redundancy.\n",
        " \t-\tFor a 90-minute movie:\n",
        " \t   - Total frames at 24fps:  90 x 60 x 24 = 129,600\n",
        " \t   - With `FRAME_SKIP = 60`, you’ll process around  129,600 / 60 = 2,160  frames per movie.\n",
        "\n",
        "*  **`BATCH_SIZE` (Frames Processed at Once)**\n",
        "\n",
        "  This determines the number of frames processed in a single batch.\n",
        " \t-\tLarger batch sizes are computationally efficient as you can leverage batch processing in libraries like OpenCV.\n",
        " \t-\tHowever, too large a batch size might lead to memory limitations.\n",
        "\n",
        "  Suggested Value: `BATCH_SIZE = 20`\n",
        " \t- Processes 20 frames at a time, balancing speed and memory use.\n",
        " \t- Matches well with typical video processing setups on consumer GPUs/TPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLUSTERS_NB = 18\n",
        "CLUSTERS_NB_BW = 5\n",
        "FRAME_SKIP = 60  # Process one frame out of every FRAME_SKIP frames in order to speed up the process\n",
        "# Resize the image to RESIZE_W x RESIZE_H pixels in order to reduce complexity\n",
        "RESIZE_W = 160\n",
        "RESIZE_H = 90\n",
        "BATCH_SIZE = 20  # Number of frames to process in each batch\n",
        "\n",
        "SATURATION_FACTOR = 1.5\n",
        "SATURATION_THRESHOLD = 50\n",
        "\n",
        "# Recalculate a new palette even if it already has one\n",
        "RECALC_PALETTES = True\n",
        "# Calculate a specific movie\n",
        "MOVIE_TO_PROCESS = \"Dick Tracy\"  # Set to None to process all movies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazqExcUTobh"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxH6lzywTWCf",
        "outputId": "aa400570-501c-4175-d5a0-024f5e97b27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88U-a-Ri2No"
      },
      "source": [
        "## Google Drive movies path and movies colors list file path\n",
        "\n",
        "> **WARNING**: Don't forget to mount Google Drive first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "O8lfNyToPsyz"
      },
      "outputs": [],
      "source": [
        "MOVIES_PATH = Path(\"/content/drive/MyDrive/MOVIES/\")\n",
        "FILE_PATH = Path(\"/content/drive/MyDrive/MOVIES/movies_palettes.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmLaqrEzJqBw"
      },
      "source": [
        "# Function to save movies colors list in a JSON file on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "9ySlHF7SKIm0"
      },
      "outputs": [],
      "source": [
        "def save_as_file(data: list, file_path: Path) -> None:\n",
        "    \"\"\"Save as JSON file on Google Drive\"\"\"\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent='\\t')\n",
        "    print(f'\"{str(file_path)}\" successfully saved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP9mCshShrNN"
      },
      "source": [
        "# Build file with list of dicts with movies info\n",
        "> **WARNING**: Only to be executed if the file doesn't exist yet, otherwise it will overwrite the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "FcQ57gEu0FDz"
      },
      "outputs": [],
      "source": [
        "# subdirs: list[PosixPath] = [p for p in MOVIES_PATH.iterdir() if p.is_dir()]\n",
        "\n",
        "# movies: list[dict] = []\n",
        "\n",
        "# for p in subdirs:\n",
        "#     # Gather some info about the movie using the folders names\n",
        "#     matches: re.Match | None = re.search(r\"(.*) \\((\\d{4})\\, (.*)\\)\", p.name)\n",
        "#     # Prepare the data structure\n",
        "#     year: str | None = None\n",
        "#     director: str | None = None\n",
        "#     file_path: str | None = None\n",
        "#     if matches:\n",
        "#         title: str = matches.group(1)\n",
        "#         year  = matches.group(2)\n",
        "#         director = matches.group(3)\n",
        "#     else:\n",
        "#       title = p.name\n",
        "\n",
        "#     # Get all video files for this movie directory\n",
        "#     file_types: tuple[str] = ('*.avi', '*.mkv', '*.mp4')\n",
        "#     files_paths: list[Path] = []\n",
        "#     for file_type in file_types:\n",
        "#         files_paths.extend(p.glob(file_type))\n",
        "\n",
        "#     # Get the unique video file path for this movie directory\n",
        "#     if len(files_paths) == 1:\n",
        "#         file_path: Path = files_paths[0]\n",
        "#     else:\n",
        "#       if len(files_paths) == 0:\n",
        "#           status = \"No movie file found\"\n",
        "#           print(f'{status} for \"{title}\"')\n",
        "#       else:\n",
        "#           status = \"More than 1 video file found:\"\n",
        "#           for f in files_paths:\n",
        "#               status += f' \\\"{f.name}\\\"'\n",
        "#           print(status)\n",
        "\n",
        "#     movie: dict = {\n",
        "#         \"title\": title,\n",
        "#         \"status\": status,\n",
        "#         \"director\": director,\n",
        "#         \"year\": year,\n",
        "#         \"path\": str(file_path) if file_path else None,\n",
        "#         \"palettes\": [],\n",
        "#     }\n",
        "#     movies.append(movie)\n",
        "\n",
        "# # Sort alphabetically\n",
        "# movies.sort(key=lambda m: m[\"title\"])\n",
        "\n",
        "# # Save as file\n",
        "# save_as_file(data=movies, file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63VwJZRmuRz1"
      },
      "source": [
        "# Optional: analyze frames numbers and length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "oxDldvKPtAR5"
      },
      "outputs": [],
      "source": [
        "# for m in (pbar := tqdm(movies)):\n",
        "\n",
        "#   pbar.set_description(f'Analyzing \"{m[\"title\"]}\"')\n",
        "\n",
        "#   if m.get(\"path\") and not m.get(\"frames\"):\n",
        "#     cap = cv2.VideoCapture(str(m[\"path\"]))\n",
        "#     m[\"frames\"]: int = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#     fps: float = cap.get(cv2.CAP_PROP_FPS)\n",
        "#     if fps:\n",
        "#       m[\"length\"]: int = int(m[\"frames\"] / fps)\n",
        "\n",
        "# save_as_file(data=movies, file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWXINNXwVrCn"
      },
      "source": [
        "# Read existing movies file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGCOvIQKVqU1",
        "outputId": "03989bda-16d2-4594-9dcf-f30229ab5f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 441 movies from \"/content/drive/MyDrive/MOVIES/movies_palettes.json\".\n"
          ]
        }
      ],
      "source": [
        "with open(FILE_PATH, \"r+\", encoding=\"utf-8\") as f:\n",
        "    movies: list[dict] = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(movies)} movies from \\\"{str(FILE_PATH)}\\\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function to get runtime type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_runtype_type() -> str:\n",
        "    if int(os.environ.get(\"COLAB_GPU\", 0)) > 0:\n",
        "        return \"GPU\"\n",
        "    elif \"TPU_DRIVER_MODE\" in os.environ and os.environ[\"TPU_DRIVER_MODE\"] == \"tpu\":\n",
        "        return \"TPU\"\n",
        "    elif \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "        return \"TPU\"\n",
        "    return \"unknown\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function to build a UUID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_palette_id(title: str, calculation_date: str) -> str:\n",
        "    \"\"\"Generate a short unique identifier for a palette\"\"\"\n",
        "    unique_string = f\"{title}_{calculation_date}\"\n",
        "    hash_object = hashlib.md5(unique_string.encode())\n",
        "    return hash_object.hexdigest()[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNY-5VRFVuWR"
      },
      "source": [
        "# Main logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the main logic here. It might takes a few minutes to a few hours per movie file, depending on where it's run.\n",
        "\n",
        "I suggest a GPU on Google Colab as the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_black_and_white(cap: cv2.VideoCapture, threshold: float = 0.1) -> bool:\n",
        "    \"\"\"\n",
        "    Determine if a movie is black and white based on the average saturation.\n",
        "\n",
        "    Parameters:\n",
        "    cap (cv2.VideoCapture): The video capture object.\n",
        "    threshold (float): The saturation threshold below which the movie is considered B&W.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the movie is black and white, False otherwise.\n",
        "    \"\"\"\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    sample_frames = min(total_frames, 100)  # Sample up to 100 frames\n",
        "\n",
        "    saturation_values = []\n",
        "    for i in range(0, total_frames, max(1, total_frames // sample_frames)):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        saturation = hsv[:, :, 1].mean() / 255.0  # Normalize to [0,1]\n",
        "        saturation_values.append(saturation)\n",
        "\n",
        "    average_saturation = np.mean(saturation_values)\n",
        "    return average_saturation < threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "1cE8M76lA8Gt"
      },
      "outputs": [],
      "source": [
        "def get_dominant_colors(\n",
        "    data: np.ndarray, clusters_nb: int\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Cluster pixels using k-means and return the dominant colors.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray): A 2D array where each row is a pixel in RGB format.\n",
        "    clusters_nb (int): The number of clusters to form.\n",
        "\n",
        "    Returns:\n",
        "    tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
        "        - centers (np.ndarray): The RGB values of the cluster centers.\n",
        "        - labels (np.ndarray): The label of the cluster each pixel belongs to.\n",
        "    \"\"\"\n",
        "    criteria: tuple[int, int, float] = (\n",
        "        cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,\n",
        "        10,\n",
        "        1.0,\n",
        "    )\n",
        "    flags: int = cv2.KMEANS_RANDOM_CENTERS\n",
        "    compactness: float\n",
        "    labels: np.ndarray\n",
        "    centers: np.ndarray\n",
        "    compactness, labels, centers = cv2.kmeans(\n",
        "        data.astype(np.float32), clusters_nb, None, criteria, 10, flags\n",
        "    )\n",
        "    return centers, labels\n",
        "\n",
        "\n",
        "def get_dominant_luminances(\n",
        "    data: np.ndarray, clusters_nb: int\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Find the dominant luminance values in an image using k-means clustering.\n",
        "    Returns these luminance values as grayscale RGB values (where R=G=B).\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray): Input image (can be color or grayscale)\n",
        "    clusters_nb (int): Number of luminance levels to identify\n",
        "\n",
        "    Returns:\n",
        "    tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
        "        - centers (np.ndarray): Array of shape (clusters_nb, 3) where each row is\n",
        "          a grayscale RGB value [v,v,v] representing a dominant luminance level\n",
        "        - labels (np.ndarray): Array indicating which cluster each pixel belongs to\n",
        "    \"\"\"\n",
        "    # Convert to grayscale if input is color image\n",
        "    if len(data.shape) > 2:\n",
        "        data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Reshape to 1D array for clustering\n",
        "    data_reshaped = data.reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "    # Define k-means parameters\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "\n",
        "    # Perform k-means clustering on luminance values\n",
        "    _, labels, centers = cv2.kmeans(\n",
        "        data_reshaped, clusters_nb, None, criteria, 10, flags\n",
        "    )\n",
        "\n",
        "    # Sort centers from darkest to lightest\n",
        "    sort_idx = np.argsort(centers.flatten())\n",
        "    centers = centers[sort_idx]\n",
        "\n",
        "    # Convert luminance values to RGB format (all channels equal)\n",
        "    # e.g., luminance value 127 becomes [127, 127, 127]\n",
        "    centers_rgb = np.column_stack([centers.flatten()] * 3)\n",
        "\n",
        "    return centers_rgb, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "IGmG2Fj8U_Lv"
      },
      "outputs": [],
      "source": [
        "def get_salient_mask(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generates a saliency mask for the input image, highlighting the most important\n",
        "    (salient) regions based on a Spectral Residual model.\n",
        "\n",
        "    Parameters:\n",
        "    image (np.ndarray): The input color image in BGR format.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: A binary saliency map (uint8), where pixel values range from 0 to 255,\n",
        "                with high values indicating salient regions.\n",
        "    \"\"\"\n",
        "    # Convert the image to grayscale\n",
        "    gray: np.ndarray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create a saliency detector object using the Spectral Residual model\n",
        "    saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
        "\n",
        "    # Compute the saliency map\n",
        "    _, saliency_map = saliency.computeSaliency(gray)\n",
        "\n",
        "    # Return the saliency map scaled to the range [0, 255] and cast to uint8\n",
        "    return (saliency_map * 255).astype(\"uint8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "IRBSkG08U0Z6"
      },
      "outputs": [],
      "source": [
        "def enhance_saturation(image: np.ndarray, factor: float, threshold: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Enhance the saturation of an image and filter out low-saturation pixels.\n",
        "\n",
        "    Parameters:\n",
        "    image (np.ndarray): The input image in BGR format.\n",
        "    factor (float): The factor by which to enhance saturation.\n",
        "    threshold (int): The saturation threshold below which pixels are filtered out.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The enhanced image with low-saturation pixels masked to black.\n",
        "    \"\"\"\n",
        "    # Convert image to HSV color space\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Enhance the saturation\n",
        "    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * factor, 0, 255)\n",
        "\n",
        "    # Create a mask for pixels with sufficient saturation\n",
        "    saturation_mask = hsv[:, :, 1] > threshold\n",
        "\n",
        "    # Apply the mask to filter low-saturation pixels (set to black)\n",
        "    hsv[~saturation_mask] = 0\n",
        "\n",
        "    # Convert back to BGR color space\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "KbifW4QnT1EU"
      },
      "outputs": [],
      "source": [
        "def process_frame(frame: np.ndarray, is_bw: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Process a single frame to extract dominant colors or luminance values.\n",
        "\n",
        "    Parameters:\n",
        "    frame (np.ndarray): The input frame\n",
        "    is_bw (bool): Whether to process as black and white\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Centers\n",
        "    \"\"\"\n",
        "    # To reduce complexity, resize the image\n",
        "    resized_frame = cv2.resize(frame, (RESIZE_W, RESIZE_H))\n",
        "\n",
        "    if is_bw:\n",
        "        centers, labels = get_dominant_luminances(resized_frame, CLUSTERS_NB_BW)\n",
        "\n",
        "    else:\n",
        "        # Enhance saturation\n",
        "        enhanced_frame = enhance_saturation(\n",
        "            image=resized_frame,\n",
        "            factor=SATURATION_FACTOR,\n",
        "            threshold=SATURATION_THRESHOLD,\n",
        "        )\n",
        "\n",
        "        # # Apply saliency detection\n",
        "        # salient_mask = get_salient_mask(data)\n",
        "        # salient_mask = salient_mask > 128  # Convert to binary mask\n",
        "        # data = frame[salient_mask]  # Apply mask to RGB channels\n",
        "\n",
        "        # # Filter out low-luminance colors\n",
        "        # luminance = centers[:, 0]\n",
        "        # valid_indices = luminance > 50\n",
        "        # centers = centers[valid_indices]\n",
        "        # # If no valid colors remain, return empty results\n",
        "        # if centers.size == 0:\n",
        "        #     return np.empty((0, 3)), np.empty((0,))\n",
        "\n",
        "        # Convert to LAB for better perceptual clustering\n",
        "        # Generate a Numpy array of 2 dimensions, and shape of (10000, 3) (1000)\n",
        "        lab_data = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2LAB).reshape(-1, 3)\n",
        "        # Get clusters in LAB space\n",
        "        centers, labels = get_dominant_colors(lab_data, CLUSTERS_NB)\n",
        "        # Convert centers back to BGR\n",
        "        centers = cv2.cvtColor(\n",
        "            centers.reshape(-1, 1, 3), \n",
        "            cv2.COLOR_LAB2BGR\n",
        "        ).reshape(-1, 3)\n",
        "\n",
        "    # Count and sort by frequency by sorting centers by cluster size (largest first)\n",
        "    # Put the CLUSTERS_NB colors in a list\n",
        "    # For example: [4450 2148 745 2048 609]\n",
        "    cluster_sizes = np.bincount(labels.flatten())\n",
        "    sorted_indices = np.argsort(-cluster_sizes)  # negative for descending order\n",
        "\n",
        "    return centers[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Nj3utgF0xivo"
      },
      "outputs": [],
      "source": [
        "def process_movie(movie: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate the palette for a movie and save the updated movies palettes files.\n",
        "\n",
        "    Parameters:\n",
        "    movie (dict): the movie details from the movies list.\n",
        "    \"\"\"\n",
        "    start_time: float = time.time()  # Record the start time\n",
        "\n",
        "    cap = cv2.VideoCapture(str(movie[\"path\"]))\n",
        "    frames_count: int = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Detect if movie is black and white\n",
        "    is_bw: bool = is_black_and_white(cap)\n",
        "\n",
        "    if is_bw:\n",
        "        pbar.set_description(\n",
        "            f'Processing B&W movie \"{movie[\"title\"]}\", with {frames_count} frames.'\n",
        "        )\n",
        "    else:\n",
        "        pbar.set_description(\n",
        "            f'Processing color movie \"{movie[\"title\"]}\", with {frames_count} frames.'\n",
        "        )\n",
        "\n",
        "    frame_nb = 0\n",
        "    colors: list[np.ndarray] = []\n",
        "\n",
        "    with tqdm(total=frames_count // FRAME_SKIP, desc=\"Frames processed\") as frame_pbar:\n",
        "        while frame_nb < frames_count:\n",
        "            # Extract a batch of images/frames\n",
        "            batch_frames: list[np.ndarray] = []\n",
        "            for _ in range(BATCH_SIZE):\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nb)\n",
        "                status, frame = cap.read()\n",
        "                frame_nb += FRAME_SKIP\n",
        "                if not status:\n",
        "                    print(f\"Frame {frame_nb} could not be read. Skipping.\")\n",
        "                    break\n",
        "                batch_frames.append(frame)\n",
        "\n",
        "            if not batch_frames:\n",
        "                break\n",
        "\n",
        "            for frame in batch_frames:\n",
        "                frame_colors = process_frame(frame, is_bw)\n",
        "                colors.extend(frame_colors)\n",
        "\n",
        "            frame_pbar.update(len(batch_frames))\n",
        "\n",
        "    # Convert list of colors for this movie to a Numpy array\n",
        "    colors = np.array(colors)\n",
        "\n",
        "    if len(colors) == 0:\n",
        "        print(f\"No colors extracted for {movie['title']}. Skipping.\")\n",
        "        return movie\n",
        "\n",
        "    # Final clustering on all collected colors\n",
        "    all_colors = np.vstack(colors)\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=CLUSTERS_NB if not is_bw else CLUSTERS_NB_BW, n_init=\"auto\"\n",
        "    )\n",
        "    kmeans.fit(all_colors)\n",
        "    final_colors = kmeans.cluster_centers_\n",
        "\n",
        "    # Calculate the total processing duration\n",
        "    end_time: float = time.time()  # Record the end time\n",
        "    duration: int = int(end_time - start_time)  # Duration in seconds\n",
        "\n",
        "    # Calculation date\n",
        "    now: str = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    palette: dict = {\n",
        "        # Add the parameters it used to calculate the colors\n",
        "        \"id\": generate_palette_id(title=movie[\"title\"], calculation_date=now),\n",
        "        \"calculation_date\": now,\n",
        "        \"calculation_duration_seconds\": duration,\n",
        "        \"runtime\": get_runtype_type(),\n",
        "        \"is_black_and_white\": is_bw,\n",
        "        \"clusters_nb\": CLUSTERS_NB_BW if is_bw else CLUSTERS_NB,\n",
        "        \"frame_skip\": FRAME_SKIP,\n",
        "        \"saturation_factor\": SATURATION_FACTOR,\n",
        "        \"saturation_threshold\": SATURATION_THRESHOLD,\n",
        "        \"resize\": {\"width\": RESIZE_W, \"height\": RESIZE_H},\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        # Convert the cluster centers to integers (RGB values)\n",
        "        \"colors\": final_colors.astype(int).tolist(),\n",
        "    }\n",
        "    movie[\"palettes\"].append(palette)\n",
        "\n",
        "    # Debug: display output\n",
        "    print(f'Colors for \"{movie[\"title\"]}\":')\n",
        "    for color in palette[\"colors\"]:\n",
        "        img = Image.new(mode=\"RGB\", size=(200, 30), color=tuple(color))\n",
        "        display(img)\n",
        "\n",
        "    return movie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final loop through movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "3e0f8d2a7a694736b44acc44df07c2ab",
            "170e834ab0e64dacb7129c64975f62a4",
            "f2b405431b304766ae134bf696b54846",
            "019d3f86c4d344babc59ea3f18750822",
            "f434fcf6c0e44f37ba1660f4ace85fc5",
            "0cc21e0b7a3b4329af6764f4e4737259",
            "273acf1e56154ca8b4dc5d72407634b9",
            "d93a75ef5bb9467abfae7808bfbc41d5",
            "0289042e51274acaa68745c909cc7381",
            "4c5711bf58144f5699d79f0123163c8d",
            "1663a2f50fed45498bcef462930021a6",
            "8db6803daa754027a333d1c06e0b0fe5",
            "43626aaac7f1444b8680b87f8b168b38",
            "8ae6f026806a452ab86c5a0adaf0d505",
            "59745b34f30244cca8699baddc5f522c",
            "464651b8acb54b31bf797b60b0ad1532",
            "c463ff9229cb4d1183e75db58331a9eb",
            "997205f8234c4f02b246c223b076224a",
            "b77f51a086154125809c36294047ade7",
            "0007c32d1d3c4df5bd18862c36216db4",
            "3e7f9c5fe49246749558c91801a1fec3",
            "3f3e1decd4c84acf93b44b18c6644767"
          ]
        },
        "id": "YQmBbkMxgqT6",
        "outputId": "9cbc36ad-dd86-4bd1-c8ac-d699486f9346"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e0f8d2a7a694736b44acc44df07c2ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/441 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8db6803daa754027a333d1c06e0b0fe5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Frames processed:   0%|          | 0/3106 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for m in (pbar := tqdm(movies)):\n",
        "    # Skip movies not matching MOVIE_TO_PROCESS, if specified\n",
        "    if MOVIE_TO_PROCESS and m[\"title\"] != MOVIE_TO_PROCESS:\n",
        "        continue\n",
        "\n",
        "    if len(m[\"palettes\"]) > 0 and not RECALC_PALETTES:\n",
        "        print(\n",
        "            f'\"{m[\"title\"]}\" already has at least one color palette calculated, skipping...'\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    if not m.get(\"path\"):\n",
        "        print(f'\"{m[\"title\"]}\" has no filepath, skipping...')\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "        updated_m: dict = process_movie(m)\n",
        "        movies[movies.index(m)] = updated_m\n",
        "        data: dict = {\n",
        "            \"last_updated\": datetime.now(timezone.utc).isoformat(),\n",
        "            \"movies\": movies,\n",
        "        }\n",
        "        save_as_file(data=data, file_path=FILE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cim2Z_WAW887"
      },
      "source": [
        "# Test: display colors palettes for each movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7evqEOXX9LQ"
      },
      "outputs": [],
      "source": [
        "for m in (pbar := tqdm(movies)):\n",
        "    if len(m.get(\"palettes\")) > 0:\n",
        "        print(m[\"title\"])\n",
        "        for p in m[\"palettes\"]:\n",
        "          print(f'\\nPalette calculated on {p.get(\"calculation_date\", \"unknown\")}:')\n",
        "          for color in p[\"colors\"]:\n",
        "            img = Image.new(mode='RGB', size=(200,30), color=tuple(color))\n",
        "            display(img)\n",
        "        print(\"\\n-------------------------------------\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GP9mCshShrNN",
        "63VwJZRmuRz1",
        "cim2Z_WAW887"
      ],
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0007c32d1d3c4df5bd18862c36216db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "019d3f86c4d344babc59ea3f18750822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5711bf58144f5699d79f0123163c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_1663a2f50fed45498bcef462930021a6",
            "value": " 0/441 [00:00&lt;?, ?it/s]"
          }
        },
        "0289042e51274acaa68745c909cc7381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc21e0b7a3b4329af6764f4e4737259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1663a2f50fed45498bcef462930021a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "170e834ab0e64dacb7129c64975f62a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc21e0b7a3b4329af6764f4e4737259",
            "placeholder": "​",
            "style": "IPY_MODEL_273acf1e56154ca8b4dc5d72407634b9",
            "value": "Processing &quot;12 Monkeys (1995)&quot;, with 186407 frames.:   0%"
          }
        },
        "273acf1e56154ca8b4dc5d72407634b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e0f8d2a7a694736b44acc44df07c2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170e834ab0e64dacb7129c64975f62a4",
              "IPY_MODEL_f2b405431b304766ae134bf696b54846",
              "IPY_MODEL_019d3f86c4d344babc59ea3f18750822"
            ],
            "layout": "IPY_MODEL_f434fcf6c0e44f37ba1660f4ace85fc5"
          }
        },
        "3e7f9c5fe49246749558c91801a1fec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3e1decd4c84acf93b44b18c6644767": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43626aaac7f1444b8680b87f8b168b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c463ff9229cb4d1183e75db58331a9eb",
            "placeholder": "​",
            "style": "IPY_MODEL_997205f8234c4f02b246c223b076224a",
            "value": "Frames processed:   7%"
          }
        },
        "464651b8acb54b31bf797b60b0ad1532": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5711bf58144f5699d79f0123163c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59745b34f30244cca8699baddc5f522c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7f9c5fe49246749558c91801a1fec3",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3e1decd4c84acf93b44b18c6644767",
            "value": " 220/3106 [00:41&lt;09:46,  4.92it/s]"
          }
        },
        "8ae6f026806a452ab86c5a0adaf0d505": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77f51a086154125809c36294047ade7",
            "max": 3106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0007c32d1d3c4df5bd18862c36216db4",
            "value": 220
          }
        },
        "8db6803daa754027a333d1c06e0b0fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43626aaac7f1444b8680b87f8b168b38",
              "IPY_MODEL_8ae6f026806a452ab86c5a0adaf0d505",
              "IPY_MODEL_59745b34f30244cca8699baddc5f522c"
            ],
            "layout": "IPY_MODEL_464651b8acb54b31bf797b60b0ad1532"
          }
        },
        "997205f8234c4f02b246c223b076224a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b77f51a086154125809c36294047ade7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c463ff9229cb4d1183e75db58331a9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93a75ef5bb9467abfae7808bfbc41d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b405431b304766ae134bf696b54846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93a75ef5bb9467abfae7808bfbc41d5",
            "max": 441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0289042e51274acaa68745c909cc7381",
            "value": 0
          }
        },
        "f434fcf6c0e44f37ba1660f4ace85fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
